# 25 processors for mini Real
#  kubectl exec -it test-pod -- /bin/bash
apiVersion: batch/v1
kind: Job
metadata:
  name: xavier-zdm-test-ps
spec:
  backoffLimit: 0
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: NotIn
                values:
                  - k8s-chase-ci-01.noc.ucsb.edu
                  - ucm-fiona01.ucmerced.edu
              - key: nvidia.com/gpu.product
                operator: In
                values:
                  - NVIDIA-GeForce-GTX-1080-Ti
      containers:
      - name: container
        image: localhost:30081/profxj/zdm_docker:latest  # UPDATE
        imagePullPolicy: Always
        resources:
          requests:
            cpu: "1"
            memory: "1Gi"  # 
            ephemeral-storage: 20Gi  # 
          limits:
            cpu: "2"
            memory: "2Gi"
            ephemeral-storage: 100Gi
            #nvidia.com/gpu:  "1"  # See docs to exlude certain types
        command: ["/bin/bash", "-c"]
        args:
          - cd FRB/FRB;
            git fetch;
            git pull;
            python setup.py develop;
            cd ../ne2001;
            python setup.py develop;
            cd ../zdm;
            git fetch;
            git checkout testing_Ps;
            python setup.py develop;
            cd zdm/data/Surveys;
            aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp s3://zdm/Surveys . --recursive --force;
            cd ../../..;
            cd papers/H0_I/Analysis/Testing/Ps;
            python test_cube.py;
            aws --endpoint http://rook-ceph-rgw-nautiluss3.rook s3 cp local_cube_test.dat s3://zdm/Testing/local_cube_test.dat --force;
        env:
          - name: "ENDPOINT_URL"
            value: "http://rook-ceph-rgw-nautiluss3.rook"
          - name: "S3_ENDPOINT"
            value: "rook-ceph-rgw-nautiluss3.rook"
        volumeMounts:
          - name: prp-s3-credentials
            mountPath: "/root/.aws/credentials"
            subPath: "credentials"
          - name: ephemeral
            mountPath: "/tmp"
          - name: "dshm"
            mountPath: "/dev/shm"
      nodeSelector:
        nautilus.io/disktype: nvme
      restartPolicy: Never
      volumes:
        # Secrets file for nautilus s3 credentials .aws/credentials and .s3cfg
        - name: prp-s3-credentials
          secret:
            secretName: prp-s3-credentials
        # Shared memory (necessary for Python's multiprocessing.shared_memory module to work)
        - name: dshm
          emptyDir:
            medium: Memory
        # Ephemeral storage
        - name: ephemeral
          emptyDir: {}
